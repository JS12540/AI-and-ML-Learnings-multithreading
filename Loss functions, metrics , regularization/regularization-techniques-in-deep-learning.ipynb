{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f2f22cc66949c8b7ace0f09aa16554a1614f6d96"
   },
   "source": [
    "One of the most common problem data science professionals face is to avoid **overfitting**. Have you come across a situation where your model performed exceptionally well on train data, but was not able to predict test data. Or you were on the top of a competition in public leaderboard, only to fall hundreds of places in the final rankings? Well – this is the kernel for you!.\n",
    "\n",
    "# Table of Contents\n",
    "1. What is Regularization?\n",
    "2. How does Regularization help in reducing Overfitting?\n",
    "3. Different Regularization techniques in Deep Learning\n",
    "    - L2 and L1 regularization\n",
    "    - Dropout\n",
    "    - Data augmentation\n",
    "    - Early stopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "741a45b3d0e609934a5091e51dcdf0462ac79323"
   },
   "source": [
    "# What is Regularization?\n",
    "Before we deep dive into the topic, take a look at this image:\n",
    "![](https://i.ibb.co/g35FMM5/over.png)\n",
    "Have you seen this image before? As we move towards the right in this image, our model tries to learn too well the details and the noise from the training data, which ultimately results in poor performance on the unseen data.\n",
    "\n",
    "In other words, while going towards the right, the complexity of the model increases such that the training error reduces but the testing error doesn’t. This is shown in the image below.\n",
    "![](https://i.ibb.co/0cygV4y/Screen-Shot-2018-04-04-at-2-43-37-PM-768x592.png)\n",
    "\n",
    "If you’ve built a neural network before, you know how complex they are. This makes them more prone to overfitting.\n",
    "\n",
    "**Regularization** is a technique which makes slight modifications to the learning algorithm such that the model generalizes better. This in turn improves the model’s performance on the unseen data as well.\n",
    "\n",
    "# How does Regularization help reduce Overfitting?\n",
    "\n",
    "Let’s consider a neural network which is overfitting on the training data.\n",
    "![](https://i.ibb.co/gmRzQtr/over-fitting.png)\n",
    "If you have studied the concept of regularization in machine learning, you will have a fair idea that **regularization penalizes the coefficients. In deep learning, it actually penalizes the weight matrices of the nodes.**\n",
    "\n",
    "Assume that our regularization coefficient is so high that some of the weight matrices are nearly equal to zero.\n",
    "This will result in a much simpler linear network and slight underfitting of the training data.\n",
    "\n",
    "Such a large value of the regularization coefficient is not that useful. We need to optimize the value of regularization coefficient in order to obtain a well-fitted model as shown in the image below.\n",
    "![](https://i.ibb.co/CKBYWFK/under.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#data preprocessing\n",
    "import pandas as pd\n",
    "#math operations\n",
    "import numpy as np\n",
    "#machine learning\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#hyperparameter optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#support vector machine model\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "            \n",
    "from random import shuffle\n",
    "from tqdm import tqdm  \n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "Parasitized=os.listdir(\"../input/cell_images/cell_images/Parasitized/\")\n",
    "for a in Parasitized:\n",
    "    try:\n",
    "        image=cv2.imread(\"../input/cell_images/cell_images/Parasitized/\"+a)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((50, 50))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(0)\n",
    "    except AttributeError:\n",
    "        print(\"\")\n",
    "\n",
    "Uninfected=os.listdir(\"../input/cell_images/cell_images/Uninfected/\")\n",
    "for b in Uninfected:\n",
    "    try:\n",
    "        image=cv2.imread(\"../input/cell_images/cell_images/Uninfected/\"+b)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((50, 50))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(1)\n",
    "    except AttributeError:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "abaa0ad9ce913573bd6f7de818627f7c7c22dcce"
   },
   "outputs": [],
   "source": [
    "Cells=np.array(data)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "8b5b3facbd70306dd63467d51fecae05343c9c3c"
   },
   "outputs": [],
   "source": [
    "np.save(\"Cells\",Cells)\n",
    "np.save(\"labels\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "d9f816fb0c6c73a3d7b232a86fa1dbdc89e46f45"
   },
   "outputs": [],
   "source": [
    "Cells=np.load(\"Cells.npy\")\n",
    "labels=np.load(\"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "090f595f39152e82cd4d3a42529da3c67e91c088"
   },
   "outputs": [],
   "source": [
    "s=np.arange(Cells.shape[0])\n",
    "np.random.shuffle(s)\n",
    "Cells=Cells[s]\n",
    "labels=labels[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "025d220c323c84a0236ffe173c616aa53e37698a"
   },
   "outputs": [],
   "source": [
    "num_classes=len(np.unique(labels))\n",
    "len_data=len(Cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "472c4dcee4e88a3cf598483c091f3ff7c64e432d"
   },
   "outputs": [],
   "source": [
    "(x_train,x_test)=Cells[(int)(0.1*len_data):],Cells[:(int)(0.1*len_data)]\n",
    "x_train = x_train.astype('float32')/255 # As we are working on image data we are normalizing data by divinding 255.\n",
    "x_test = x_test.astype('float32')/255\n",
    "train_len=len(x_train)\n",
    "test_len=len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "4f79c9f8cb7fa7c1ea2b60006c89580224b68e8d"
   },
   "outputs": [],
   "source": [
    "(y_train,y_test)=labels[(int)(0.1*len_data):],labels[:(int)(0.1*len_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "75cd91f23a6e0836ef9f91f5be415747457c3c87"
   },
   "outputs": [],
   "source": [
    "#Doing One hot encoding as classifier has multiple classes\n",
    "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test=keras.utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33f32ca85106632abc880c0936947755ba5a4988"
   },
   "source": [
    "# Different Regularization Techniques in Deep Learning\n",
    "\n",
    "Now that we have an understanding of how regularization helps in reducing overfitting, we’ll learn a few different techniques in order to apply regularization in deep learning.\n",
    "\n",
    "## L2 & L1 regularization\n",
    "\n",
    "L1 and L2 are the most common types of regularization. These update the general cost function by adding another term known as the regularization term.\n",
    "\n",
    "### Cost function = Loss (say, binary cross entropy) + Regularization term\n",
    "\n",
    "Due to the addition of this regularization term, the values of weight matrices decrease because it assumes that a neural network with smaller weight matrices leads to simpler models. Therefore, it will also reduce overfitting to quite an extent.\n",
    "\n",
    "However, this regularization term differs in L1 and L2.\n",
    "\n",
    "In L2, we have:\n",
    "![L2](https://i.ibb.co/b3Dp6mL/L2.png)\n",
    "\n",
    "Here, **lambda** is the regularization parameter. It is the hyperparameter whose value is optimized for better results. L2 regularization is also known as weight decay as it forces the weights to decay towards zero (but not exactly zero).\n",
    "\n",
    "In L1, we have:\n",
    "\n",
    "![L2](https://i.ibb.co/zZBJrgB/l1.png)\n",
    "\n",
    "In this, we penalize the absolute value of the weights. Unlike L2, the weights may be reduced to zero here. **Hence, it is very useful when we are trying to compress our model. Otherwise, we usually prefer L2 over it.**\n",
    "\n",
    "In keras, we can directly apply regularization to any layer using the regularizers.\n",
    "Below I have applied regularizer on dense layer having 500 neurons and relu activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "2af22f0084edcb1319bea37fa93b3b944696c31f"
   },
   "outputs": [],
   "source": [
    "#creating sequential model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "#l2 regularizer\n",
    "model.add(Dense(500,kernel_regularizer=regularizers.l2(0.01),activation=\"relu\"))\n",
    "model.add(Dense(2,activation=\"softmax\"))#2 represent output layer neurons \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b472fbf7f50daf9fb2087bf75398b9d88dc525d5"
   },
   "source": [
    "**Note: Here the value 0.01 is the value of regularization parameter, i.e., lambda, which we need to optimize further. We can optimize it using the grid-search method.**\n",
    "\n",
    "Similarly, we can also apply L1 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "df2bfe53980b2fdc18e60ee3665e68589abae5d5"
   },
   "source": [
    "# Dropout\n",
    "This is the one of the most interesting types of regularization techniques. It also produces very good results and is consequently the most frequently used regularization technique in the field of deep learning.\n",
    "\n",
    "To understand dropout, let’s say our neural network structure is akin to the one shown below:\n",
    "![](https://i.ibb.co/G3PgsRs/d1.png)\n",
    "\n",
    "So what does dropout do? At every iteration, it randomly selects some nodes and removes them along with all of their incoming and outgoing connections as shown below.\n",
    "\n",
    "![](https://i.ibb.co/4pdnr5r/d2.png)\n",
    "\n",
    "So each iteration has a different set of nodes and this results in a different set of outputs. **It can also be thought of as an ensemble technique in machine learning.**\n",
    "\n",
    "Ensemble models usually perform better than a single model as they capture more randomness. Similarly, dropout also performs better than a normal neural network model.\n",
    "\n",
    "This probability of choosing how many nodes should be dropped is the hyperparameter of the dropout function. As seen in the image above, dropout can be applied to both the hidden layers as well as the input layers.\n",
    "\n",
    "![](https://i.ibb.co/KydYCbp/d3.gif)\n",
    "\n",
    "Due to these reasons, dropout is usually preferred when we have a large neural network structure in order to introduce more **randomness.**\n",
    "\n",
    "In keras, we can implement dropout using the **keras  layer**. Below is the Dropout Implementation.\n",
    "I have introduced dropout of 0.2  as the probability of dropping in my neural network architecture after last hidden layer having 64 kernels and after first dense layer having 500 neurons.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "f629ea90f54cec5a8a3e083c8551a6da471fd5f4"
   },
   "outputs": [],
   "source": [
    "#creating sequential model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "# 1st dropout\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "# 2nd dropout\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation=\"softmax\"))#2 represent output layer neurons \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "72e09ba51bf4349f4ede829195e89a7465b27d8d"
   },
   "source": [
    "# Data Augmentation\n",
    "The simplest way to reduce overfitting is to increase the size of the training data. In machine learning, we were not able to increase the size of training data as the labeled data was too costly.\n",
    "\n",
    "But, now let’s consider we are dealing with images. In this case, there are a few ways of increasing the size of the training data – rotating the image, flipping, scaling, shifting, etc. In the below image, some transformation has been done on the handwritten digits dataset.\n",
    "![](https://i.ibb.co/rd4FpW6/aug.png)\n",
    "\n",
    "This technique is known as **data augmentation**. This usually provides a big leap in improving the accuracy of the model. It can be considered as a mandatory trick in order to improve our predictions.\n",
    "\n",
    "In keras, we can perform all of these transformations using **ImageDataGenerator**. It has a big list of arguments which you you can use to pre-process your training data.\n",
    "\n",
    "Below is the implementation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "4fc0e5c9895302065d38189c892802f912de1333"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8e56fa732b101f1b08cafe112f67f3d4e7beaf7"
   },
   "source": [
    "# Early stopping\n",
    "Early stopping is a kind of cross-validation strategy where we keep one part of the training set as the validation set. When we see that the performance on the validation set is getting worse, we immediately stop the training on the model. This is known as **early stopping.**\n",
    "\n",
    "![](https://i.ibb.co/CmJpR3R/early.png)\n",
    "In the above image, we will stop training at the dotted line since after that our model will start overfitting on the training data.\n",
    "\n",
    "In keras, we can apply early stopping using the **callbacks** function. Below is the implementation code for it.I have applied early stopping so that it will stop immendiately if validation error will not decreased after 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "778bb1ffe1d519cc594855c02948629644231f4d"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop= EarlyStopping(monitor='val_acc', patience=3)\n",
    "epochs = 20 # \n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f4df5c03bc61d5b9473fb852044de7dff44e3b5a"
   },
   "source": [
    "Here, **monitor** denotes the quantity that needs to be monitored and **‘val_err’** denotes the validation error.\n",
    "\n",
    "**Patience** denotes the number of epochs with no further improvement after which the training will be stopped. For better understanding, let’s take a look at the above image again. After the dotted line, each epoch will result in a higher value of validation error. Therefore, 5 epochs after the dotted line (since our patience is equal to 3), our model will stop because no further improvement is seen.\n",
    "\n",
    "**Note: It may be possible that after 3 epochs (this is the value defined for patience in general), the model starts improving again and the validation error starts decreasing as well. Therefore, we need to take extra care while tuning this hyperparameter.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8289e287f425c17b47569bec167af89ff6f81749"
   },
   "source": [
    "# Implementation on Malaria Cell Identification with keras\n",
    "By this point, you should have a theoretical understanding of the different techniques we have gone through. We will now apply this knowledge to our deep learning practice problem – Identify Malaria cell. \n",
    "In this problem I will use all the regularization techniques which I have discussed earlier i.e., \n",
    "1. L1,L2 Regularizer\n",
    "2. Dropout\n",
    "3. Data Augmentation\n",
    "4. Early Stopping\n",
    "Now Let's start firing bullets !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "ffda6b96e883e7d4281e2af6b43b6dbdfdc473ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               1152500   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 1,164,046\n",
      "Trainable params: 1,164,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating sequential model\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "# 1st dropout\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "#l2 regularizer\n",
    "model.add(Dense(500,kernel_regularizer=regularizers.l2(0.01),activation=\"relu\"))\n",
    "# 2nd dropout\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation=\"softmax\"))#2 represent output layer neurons \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "69dae93c995c17a2c1e15a23f62f2e56ed5cffe1"
   },
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "# compile the model with loss as categorical_crossentropy and using adam optimizer you can test result by trying RMSProp as well as Momentum\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "1c06b66a9ba37f8fd7609ea3d3e0695c2f3af004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "96/96 [==============================] - 37s 384ms/step - loss: 1.8363 - acc: 0.6534 - val_loss: 0.5456 - val_acc: 0.7572\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 35s 365ms/step - loss: 0.4570 - acc: 0.8349 - val_loss: 0.4226 - val_acc: 0.8726\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 35s 365ms/step - loss: 0.3233 - acc: 0.9018 - val_loss: 0.3744 - val_acc: 0.8940\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 35s 362ms/step - loss: 0.2808 - acc: 0.9165 - val_loss: 0.2909 - val_acc: 0.9136\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 35s 367ms/step - loss: 0.2674 - acc: 0.9218 - val_loss: 0.2328 - val_acc: 0.9379\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 35s 368ms/step - loss: 0.2563 - acc: 0.9309 - val_loss: 0.2461 - val_acc: 0.9310\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 35s 364ms/step - loss: 0.2495 - acc: 0.9344 - val_loss: 0.2504 - val_acc: 0.9336\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 34s 359ms/step - loss: 0.2444 - acc: 0.9387 - val_loss: 0.2672 - val_acc: 0.9314\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (x_test,y_test),\n",
    "                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                              , callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0847ce4de2fa9510cf9956da852bf55b7b59cc3"
   },
   "source": [
    "### !!! Great we achived 95.10% validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "824b11937fd9ca33679bea75c307d61317fdcdf5"
   },
   "source": [
    "Now plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "ef2abb7585f0e1f27a7180b2cd5cd5ccba46310b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "y_true = np.argmax(y_test,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "ea6c027d90e5fca0f51c5be2ad6f71262dc1a399"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CM = confusion_matrix(y_true, pred)\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "7c605ecef990d1735ed577d0fe4e8a58b45dcb48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9371841155234657"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recall=1298/(1298+87)\n",
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "d6d03f006c96a7fdc82706b1fdde8eb6efdb8684"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9643387815750372"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision = 1298/(1298+48)\n",
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "95cd5045f17b1d4fde4d862b102ae0ea02ffa0df"
   },
   "source": [
    "# Please hit Upvote if you really like this kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "d0d2f56c414173cc860f1848ad4c25e7123c24aa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
